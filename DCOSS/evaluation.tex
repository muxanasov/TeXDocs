\section{Evaluation}\label{sec:eval}

In this section we show the evaluation of our approach. To this end, we
developed several scenarios for WSNs and compare nesC implementations against
its ConesC-written analogs. In addition to the main motivating example shown
in Sec.~\ref{sec:appdesign}, we describe two more applications for WSNs.

\subsection{Scenarios}\label{sec:scenarios}

The diagram on Fig.~\ref{fig:shd} displays the possible application of a
Smart-Home scenario, where each room is supplied with one node. The latter
detects a \emph{Light Intensity} and \emph{Climate} by using corresponding
sensors. The node uses actuators to adjusts the luminosity and climate according
to thresholds given by current \emph{Preferences}. The latter depends on the
time of the day and the day of the week. On the other hand, the system
provides safety by exploiting camera, accelerometer, fire and smoke sensors.
Should the node detect a significant movement, it enables GPRS and sends alert
messages with camera images to the Police. In case of \emph{Fire}, the node
calls the Fire service and communicates with other nodes to allow a householder
to leave the house safely.

\putfigure{caption=Smart-home diagram.,label=fig:shd}{
 \centering
 \includegraphics[width=\columnwidth]{pdf/smarthome}
}

Another scenario - a system-level adaptation - is shown on Fig.~\ref{fig:apd}.
If the network is static, it is feasible to use a \emph{Collection Tree
Protocol}. In mobile network, however, a \emph{Gossip}-based protocol shows
better results. Orthogonally to the \emph{Protocol type}, developer may want to
adjust the \emph{Protocol parameters} to enhance a link quality between nodes,
increase the lifetime of the network or use the bandwidth more effectively.

\putfigure{caption=Adaptive protocol diagram.,label=fig:apd}{
 \centering
 \includegraphics[width=\columnwidth]{pdf/system-level}
}

\subsection{Coupling}\label{sec:evalcomp}

According to the work of Stevens et al.~\cite{stevens79}, there are seven types
of coupling, which are summarized in Table~\ref{tab:couptypes}. It is generally
known that the tightest coupling is, the more difficult is debugging,
maintaining and reusing the program. Coupling types, which are presented in this section, are not forbidden in ConesC, but some of them can be easily avoided with a proper use of its concepts. The result of our analysis, which is displayed on Table~\ref{tab:coupres}, shows that ConesC
implementation is much more decoupled as compared to its nesC counterpart. 

Both implementations have~\emph{External} and~\emph{Data} couplings, since the application is processing the same data differently depending on the current state -- i.e. context in terms of ConesC -- and typed interfaces are used to share the data among modules. We did not use, however, neither messages to share data nor different parts of the same data format, so~\emph{Stamp} and~\emph{Message} couplings are avoided in both implementations.

Implementation of context components in ConesC, example of which are presented in Fig.~\ref{fig:cc} and~\ref{fig:irc}, do not rely on internal work of each other, so the are not coupled in the sense of~\emph{Content coupling}, as compared to nesC-written application, where all the behavioral variations are encapsulated in one module or function. Since each context represents a separate state of the environment or the device the system operates in, contexts are not intended to share any global states, to control the flow of each other and to pass the information how to execute. Our abstraction toward~\emph{context
groups} allows developers to perform system-level operations -- e.g. data storage --
orthogonally to the data processing without actual modules coupling involved.

\begin{table}[!h]
\renewcommand{\arraystretch}{1.3}
\caption{Coupling types.}
\label{tab:couptypes}
\input{tab_couptypes}
\end{table}

\begin{table}[!h]
\renewcommand{\arraystretch}{1.3}
\caption{Coupling comparison.}
\label{tab:coupres}
\input{tab_coupres}
\end{table}

\subsection{Complexity} 

We estimate the complexity of the program by making use of such indicators as the number of
lines of code (LOC), the number of variable declaration and the number of
functions~\cite{pressman01}. Our results are illustrated on
Table~\ref{tab:compres}. Despite the overall increase of complexity of the whole
application, there is a significant reduction of the per-module complexity.
Context-oriented approach makes a program logically
fragmented, which increases the number of modules -- e.g.~\emph{contexts}
and~\emph{context configurations} -- and boilerplate code. Because of the same
reason, functions have to be spitted into smaller isolated parts. We believe, however,
that in larger applications the number of the similar lines of code will be bigger.
The number of LOC can also be decreased significantly -- as shown in Table~\ref{tab:compres} in
parentheses -- by having a tool, which generates a boilerplate code using a diagram of a
context-oriented model of the application, similar to the one displayed in
Fig.~\ref{fig:wtd}. The logical fragmentation leads to a code simplification,
improved readability and re-useability along with easier debugging and maintaining processes.

Considering the size of source code generated by translator, as shown on
Table~\ref{tab:compres}, we notice that the program written in context-oriented
style using plane nesC  is more than 3 times bigger than its ConesC counterpart. Our
approach makes context-oriented programming as simple as plain nesC programming.

\begin{table}[!h]
\renewcommand{\arraystretch}{1.3}
\caption{Complexity comparison.}
\label{tab:compres}
\input{tab_compres}
\end{table}

\subsection{CPU and memory overhead}

Here we discuss a CPU overhead for context transitions and calls of layered
functions, as well as memory overhead of using ConesC as compared to nesC. To perform a CPU
overhead comparison we use MSPSim emulator~\cite{eriksson09}, while memory overhead was
simply estimated by a nesC compiler at binary generation.

Since there are neither contexts nor layered functions in nesC-based
implementation, we measured a number of CPU-cycles of parts with different
execution flow. For example, contextual events, like a base station presence,
are detected and handled in ConesC differently as compared to nesC, but,
eventually, it results in the same functionality. 

Our evaluation -- which is displayed in Fig.~\ref{fig:cmo} -- shows that average
CPU overhead of layered function call is from 2 to 5 CPU cycles, depending on the
application. The overhead in ConesC is negligible in terms of energy consumption,
since it is even lesser than the simplest operation in TinyOS -- turning on/off
LEDs -- consumes 8 CPU-cycles. The overhead of context transitions is bigger
than the latter, but has the same order of magnitude $\approx1$.

Memory overhead is shown in Fig.~\ref{fig:memo}, where we have less than 2.5\%
overhead for binary size and less than 4.5\% overhead for RAM usage.

\putfigure{caption=CPU and memory overhead.,label=fig:cmo}{
\centering
\subfloat[CPU overhead.]{
  \includegraphics[width =0.5\columnwidth]{pdf/cpu_overhead}
  \label{fig:cpuo}
}
\subfloat[Memory overhead.]{
  \includegraphics[width=0.5\columnwidth]{pdf/memory_overhead}
  \label{fig:memo}
}
}
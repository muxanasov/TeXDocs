\section{Evaluation}\label{sec:eval}

In this section we show the evaluation of our approach. To this end, we compare
implementations of wildlife tracking application using nesC against its ConesC-written analog.

\subsection{Coupling}\label{sec:evalcomp}

According to the work of Stevens et al.~\cite{stevens79}, there are seven types
of coupling, which are summarized in Table~\ref{tab:couptypes}. It is generally
known that the tightest coupling is, the more difficult is debugging,
maintaining and reusing the program. Coupling types, which are presented in this section, are not forbidden in ConesC, but some of them can be easily avoided with a proper use of its concepts. The result of our analysis, which is displayed on Table~\ref{tab:coupres}, shows that ConesC
implementation is much more decoupled as compared to its nesC counterpart. 

Both implementations have~\emph{External} and~\emph{Data} couplings, since the application is processing the same data differently depending on the current state -- i.e. context in terms of ConesC -- and typed interfaces are used to share the data among modules. We did not use, however, neither messages to share data nor different parts of the same data format, so~\emph{Stamp} and~\emph{Message} couplings are avoided in both implementations.

Implementation of context components in ConesC, example of which are presented in Fig.~\ref{fig:cc} and~\ref{fig:irc}, do not rely on internal work of each other, so the are not coupled in the sense of~\emph{Content coupling}, as compared to nesC-written application, where all the behavioral variations are encapsulated in one module or function. Since each context represents a separate state of the environment or the device the system operates in, contexts are not intended to share any global states, to control the flow of each other and to pass the information how to execute. Our abstraction toward~\emph{context
groups} allows developers to perform system-level operations -- e.g. data storage --
orthogonally to the data processing without actual coupling modules involved.

\begin{table}[!h]
\renewcommand{\arraystretch}{1.3}
\caption{Coupling types.}
\label{tab:couptypes}
\input{tab_couptypes}
\end{table}

\begin{table}[!h]
\renewcommand{\arraystretch}{1.3}
\caption{Coupling comparison.}
\label{tab:coupres}
\input{tab_coupres}
\end{table}

\subsection{Complexity} 

We estimate the complexity of the program by making use of such indicators as the number of
lines of code (LOC), the number of variable declaration and the number of
functions~\cite{pressman01}. Our results are illustrated on
Table~\ref{tab:compres}. Despite the overall increase of complexity of the whole
application, there is a significant reduction of the per-module complexity.
Context-oriented approach makes a program logically
fragmented, which leads to increased number of modules -- e.g.~\emph{contexts}
and~\emph{context configurations} -- and boilerplate code. Because of the same
reason, functions have to be spitted into smaller isolated parts. We believe, however,
that in larger applications the number of the similar lines of code will be bigger.
The number of LOC can also be decreased significantly -- as showed in Table~\ref{fig:compres} in
parentheses -- by having a tool, which generates a boilerplate code using a diagram of a
context-oriented model of the application, similar to the one displayed in Fig.~\ref{fig:wtd}.
The isolation leads to a code simplification, improved
readability and re-useability along with easier debugging process.

\begin{table}[!h]
\renewcommand{\arraystretch}{1.3}
\caption{Complexity comparison.}
\label{tab:compres}
\input{tab_compres}
\end{table}

\subsection{CPU and memory overhead}

Here we discuss a CPU overhead for context transitions and calls of layered
functions, as well as memory overhead of using ConesC as compared to nesC. To perform a CPU
overhead comparison we use MSPSim emulator~\cite{eriksson09}, while memory overhead was
simply estimated by a nesC compiler at the binary generation.

Since there are neither contexts nor layered functions in nesC-based
implementation, we measured a number of CPU-cycles of parts with different
execution flow. For example, contextual events, like a base station presence,
are detected and handled in ConesC differently as compared to nesC, but,
eventually, it results in the same functionality. Our evaluation shows that CPU overhead of
a layered function call is from 1 to 2 -- depending on the activated context -- CPU-cycles
for~\emph{Battery},~\emph{Base Station} and~\emph{Communication} groups, and from
1 to 3 CPU-cycles for~\emph{Locator} group, which leads us to the linear dependency on the
number of contexts per group. The overhead of context transitions is slightly bigger, but still has
linear dependency on the number of contexts per group: 15 CPU-cycles
for~\emph{Battery},~\emph{Base Station} and~\emph{Communication} groups, and 20
CPU-cycles for~\emph{Locator} group in the worst case. The CPU-overhead of using ConesC is
negligible in terms of energy consumption, since it is even lesser than the simplest operation in
TinyOS -- turning on/off LEDs -- consumes 8 CPU-cycles.

As concerns memory, we have 3\% overhead for both RAM and binary sizes.
